{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"all_datasets/content_based/qualified_ratings.csv\", index_col=0)\n",
    "n_users = np.unique(ratings['userId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split users by group of number of movies they rated\n",
    "user_rating_counts = ratings['userId'].value_counts()\n",
    "\n",
    "users_50_100 = user_rating_counts[user_rating_counts <= 100].index.to_numpy()\n",
    "users_101_200 = user_rating_counts[(user_rating_counts > 100) & (user_rating_counts <= 200)].index.to_numpy()\n",
    "users_201_500 = user_rating_counts[(user_rating_counts > 200) & (user_rating_counts <= 500)].index.to_numpy()\n",
    "users_501_1000 = user_rating_counts[(user_rating_counts > 500) & (user_rating_counts <= 1000)].index.to_numpy()\n",
    "users_1001_12000 = user_rating_counts[user_rating_counts > 1000].index.to_numpy()\n",
    "# train test split for each group\n",
    "users_50_100_train, users_50_100_test = train_test_split(users_50_100, test_size=0.2, random_state=24)\n",
    "users_101_200_train, users_101_200_test = train_test_split(users_101_200, test_size=0.2, random_state=24)\n",
    "users_201_500_train, users_201_500_test = train_test_split(users_201_500, test_size=0.2, random_state=24)\n",
    "users_501_1000_train, users_501_1000_test = train_test_split(users_501_1000, test_size=0.2, random_state=24)\n",
    "users_1001_12000_train, users_1001_12000_test = train_test_split(users_1001_12000, test_size=0.2, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('all_datasets/content_based/processed_movies_info.csv', index_col=0)\n",
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = data.drop(columns=['movieId', 'title', 'imdbId', '(no genres listed)']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all columns\n",
    "scaler = StandardScaler()\n",
    "items_scaled = scaler.fit_transform(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality using TruncatedSVD after tuning n_components\n",
    "items_sparse = csr_matrix(items_scaled)\n",
    "items_reduced = TruncatedSVD(n_components=8).fit_transform(items_sparse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data scaled for Ridge since it has a built-in svd solver\n",
    "data_scaled = pd.DataFrame(items_scaled).assign(movieId=data['movieId'])\n",
    "data_reduced = pd.DataFrame(items_reduced).assign(movieId=data['movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X, y for each user\n",
    "def get_items_rated_by_user(data, filt_ratings, user_id):\n",
    "    movie_ids = filt_ratings[filt_ratings['userId'] == user_id]['movieId'].values\n",
    "    feature_vector = data[data['movieId'].isin(movie_ids)].drop(columns='movieId')\n",
    "    scores = filt_ratings[filt_ratings['userId'] == user_id]['rating'].values\n",
    "    return feature_vector, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_known_ratings_for_user(data, userId, model):\n",
    "    X, y = get_items_rated_by_user(data, ratings, userId)\n",
    "    model.fit(X, y)\n",
    "    return np.clip(model.predict(X), 0.5, 5)\n",
    "def get_not_seen_movies_from_user(data, userId):\n",
    "    user_ratings = ratings[ratings['userId'] == userId]\n",
    "    seen_movies = data['movieId'].isin(user_ratings['movieId'])\n",
    "    return data[~seen_movies].drop(columns='movieId')\n",
    "def predict_unknown_ratings_for_user(data, userId, model):\n",
    "    X, y = get_items_rated_by_user(data, ratings, userId)\n",
    "    X_test = get_not_seen_movies_from_user(userId)\n",
    "    model.fit(X, y)\n",
    "    return np.clip(model.predict(X_test), 0.5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo of hyperparameters for tuning\n",
    "ridge_param_grid = {\n",
    "  'alpha': [40, 50, 60, 70, 80, 90],\n",
    "}\n",
    "\n",
    "knn_param_grid = {\n",
    "  'n_neighbors': [30],\n",
    "}\n",
    "\n",
    "\n",
    "rf_param_grid = {\n",
    "  'n_estimators': [300],\n",
    "}\n",
    "lgbm_param_grid = {\n",
    "    'num_leaves': [2, 5, 10],\n",
    "    'min_data_in_leaf': [10, 50, 100],\n",
    "    'boosting_type': ['gbdt']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_grid_search(users, estimator, param_grid, param_grid_size, data):\n",
    "    final_rmse = np.zeros(param_grid_size)\n",
    "    final_mae = np.zeros(param_grid_size)\n",
    "    grid_search = GridSearchCV(estimator=estimator, param_grid=param_grid,\n",
    "                                scoring=('neg_root_mean_squared_error', 'neg_mean_absolute_error'), refit=False,\n",
    "                                cv=KFold(5, shuffle=True), n_jobs=-1)\n",
    "    \n",
    "    for user in users:\n",
    "        X, y = get_items_rated_by_user(data, ratings, user)\n",
    "        grid_search.fit(X, y)\n",
    "        rmse = grid_search.cv_results_['mean_test_neg_root_mean_squared_error']\n",
    "        mae = grid_search.cv_results_['mean_test_neg_mean_absolute_error']\n",
    "        final_rmse += rmse\n",
    "        final_mae += mae\n",
    "    param_df = pd.DataFrame(grid_search.cv_results_['params'])\n",
    "    param_df['rmse'] = final_rmse / len(users)\n",
    "    param_df['mae'] = final_mae / len(users)\n",
    "    return param_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo of a parameter dataframe for tuning\n",
    "param_df = customized_grid_search(users_1001_12000_train, Ridge(), ridge_param_grid, 6, data_scaled)\n",
    "param_df.to_csv('ridge_1001_12000_param.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean rmse and mae of a model on a dataset\n",
    "def evaluate_model(model, users, data):\n",
    "    final_rmse = 0\n",
    "    final_mae = 0\n",
    "    for user in users:\n",
    "        X, y = get_items_rated_by_user(data, ratings, user)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        final_rmse += root_mean_squared_error(y_test, y_pred)\n",
    "        final_mae += mean_absolute_error(y_test, y_pred)\n",
    "    return final_rmse/len(users), final_mae/len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean rmse and mae of LightGBM on a dataset\n",
    "def evaluate_lgbm(users, data):\n",
    "    final_rmse = 0\n",
    "    final_mae = 0\n",
    "    for user in users:\n",
    "        X, y = get_items_rated_by_user(data, ratings, user)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)\n",
    "        dataset = lgb.Dataset(X_train, y_train)\n",
    "        params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'l2',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'learning_rate': 0.01,\n",
    "            'num_leaves': 31,\n",
    "            'max_depth': -1,\n",
    "            'min_data_in_leaf': 5,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "        }\n",
    "        model = lgb.train(params, dataset)\n",
    "        y_pred = model.predict(X_test)\n",
    "        final_rmse += root_mean_squared_error(y_test, y_pred)\n",
    "        final_mae += mean_absolute_error(y_test, y_pred)\n",
    "    return final_rmse/len(users), final_mae/len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done train\n"
     ]
    }
   ],
   "source": [
    "# demo of evaluating model after finding optimal hyperparameter\n",
    "train_rmse, train_mae = evaluate_model(RandomForestRegressor(max_depth=20, n_jobs=-1),users_101_200_train, data_reduced)\n",
    "print(\"done training\")\n",
    "test_rmse, test_mae = evaluate_model(RandomForestRegressor(max_depth=20, n_jobs=-1) ,users_101_200_test, data_reduced)\n",
    "print(f'Train MAE: {train_mae}')\n",
    "print(f'Train RMSE: {train_rmse}')\n",
    "print(f'Test MAE: {test_mae}')\n",
    "print(f'Test RMSE: {test_rmse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
